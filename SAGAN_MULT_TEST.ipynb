{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNlG4c5hR467dmL5kv2A6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wemerson-ferr/TCC_SAGAN_IMPLEMENTATION/blob/main/SAGAN_MULT_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_Ah8PsfQbM9"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle --quiet\n",
        "!pip install torch-fidelity --quiet\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import csv\n",
        "import torch_fidelity\n",
        "from torch_fidelity.metrics import calculate_metrics\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectando ao Drive, para ler/escrever arquivos de execução.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- LÓGICA PARA CRIAR PASTA DE EXECUÇÃO ÚNICA ---\n",
        "BASE_PROJECT_PATH = '/content/drive/MyDrive/Meu_TCC_SAGAN_V2'\n",
        "os.makedirs(BASE_PROJECT_PATH, exist_ok=True)"
      ],
      "metadata": {
        "id": "mKAQ_xmJTm4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar e salvar imagens (pode ser mantida fora da função principal)\n",
        "def save_fake_images_for_evaluation(netG, device, save_path, num_images=5000):\n",
        "    print(f\"Gerando {num_images} imagens para avaliação em '{save_path}'...\")\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    batch_size = 64\n",
        "    nz = 100 # Supondo nz=100\n",
        "    for i in range(0, num_images, batch_size):\n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "            fake_images = netG(noise).detach().cpu()\n",
        "        for j in range(fake_images.size(0)):\n",
        "            img_idx = i + j\n",
        "            if img_idx < num_images:\n",
        "                vutils.save_image(fake_images[j], os.path.join(save_path, f'fake_{img_idx:05d}.png'), normalize=True)\n",
        "    print(\"Geração concluída.\")"
      ],
      "metadata": {
        "id": "epIp_w2kUQl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_latent_space_interpolation(netG, device, save_dir, hyperparameters, num_steps=10):\n",
        "    z1 = torch.randn(1, hyperparameters[\"latent_dim_nz\"], 1, 1, device=device)\n",
        "    z2 = torch.randn(1, hyperparameters[\"latent_dim_nz\"], 1, 1, device=device)\n",
        "    alpha_values = torch.linspace(0, 1, num_steps)\n",
        "    interpolated_z = torch.cat([(1 - alpha) * z1 + alpha * z2 for alpha in alpha_values], dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_images = netG(interpolated_z).detach().cpu()\n",
        "\n",
        "    grid = torchvision.utils.make_grid(fake_images, nrow=num_steps, padding=2, normalize=True)\n",
        "    plt.figure(figsize=(15, 3)); plt.imshow(grid.permute(1, 2, 0))\n",
        "    plt.title(\"Interpolação no Espaço Latente\"); plt.axis(\"off\")\n",
        "    plt.savefig(os.path.join(save_dir, 'interpolacao_latente.png')); plt.close()"
      ],
      "metadata": {
        "id": "-g1lP7oeUTJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração da API do Kaggle e Download do Dataset (faça isso uma vez)\n",
        "KAGGLE_JSON_PATH = \"/content/drive/MyDrive/Colab_Secrets/kaggle.json\"\n",
        "if not os.path.exists(\"/content/data/celebahq\"):\n",
        "    print(\"Configurando API do Kaggle e baixando o dataset...\")\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp \"{KAGGLE_JSON_PATH}\" ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    !mkdir -p /content/data\n",
        "    !kaggle datasets download -d lamsimon/celebahq -p /content/data\n",
        "    !unzip -q /content/data/celebahq.zip -d /content/data/celebahq\n",
        "    print(\"Dataset pronto!\")\n",
        "else:\n",
        "    print(\"Dataset já existe. Pulando o download.\")"
      ],
      "metadata": {
        "id": "yXSWsT9CV3xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(hyperparameters, experiment_name):\n",
        "    \"\"\"\n",
        "    Função que encapsula todo o pipeline de um experimento:\n",
        "    configuração, treinamento, avaliação e logging.\n",
        "    \"\"\"\n",
        "    # --- CRIAÇÃO DA ESTRUTURA DE PASTAS PARA O EXPERIMENTO ATUAL ---\n",
        "    PROJECT_PATH = os.path.join(BASE_PROJECT_PATH, experiment_name)\n",
        "    print(f\"Pasta da execução definida como: {PROJECT_PATH}\")\n",
        "\n",
        "    IMAGES_PATH = os.path.join(PROJECT_PATH, 'imagens_geradas')\n",
        "    CHECKPOINTS_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
        "    LOGS_PATH = os.path.join(PROJECT_PATH, 'logs')\n",
        "    EVAL_IMAGES_BASE_PATH = os.path.join(PROJECT_PATH, 'imagens_para_avaliacao') # ### MUDANÇA ###: Pasta base para imagens de avaliação\n",
        "\n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    os.makedirs(CHECKPOINTS_PATH, exist_ok=True)\n",
        "    os.makedirs(LOGS_PATH, exist_ok=True)\n",
        "    os.makedirs(EVAL_IMAGES_BASE_PATH, exist_ok=True) # ### MUDANÇA ###: Cria a pasta base\n",
        "\n",
        "\n",
        "    # Salva os hiperparâmetros em um arquivo JSON\n",
        "    with open(os.path.join(PROJECT_PATH, 'hyperparameters.json'), 'w') as f:\n",
        "        json.dump(hyperparameters, f, indent=4)\n",
        "\n",
        "    # Configurações do dispositivo e transformações\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(hyperparameters[\"image_size\"]),\n",
        "        transforms.CenterCrop(hyperparameters[\"image_size\"]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    # Carregar o Dataset com o Dataloader\n",
        "    # O download e descompactação podem ser feitos uma vez fora da função se o dataset não mudar\n",
        "    dataset = torchvision.datasets.ImageFolder(root=\"/content/data/celebahq\", transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=True, num_workers=4)\n",
        "\n",
        "    # Definições das classes SelfAttention, Generator, Discriminator e função weights_init\n",
        "    class SelfAttention(nn.Module):\n",
        "        def __init__(self, in_channels):\n",
        "            super().__init__()\n",
        "            self.query = spectral_norm(nn.Conv2d(in_channels, in_channels // 8, 1))\n",
        "            self.key = spectral_norm(nn.Conv2d(in_channels, in_channels // 8, 1))\n",
        "            self.value = spectral_norm(nn.Conv2d(in_channels, in_channels, 1))\n",
        "            self.gamma = nn.Parameter(torch.tensor(0.0)) # Parâmetro de escala aprendível\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, C, H, W = x.size()\n",
        "            query = self.query(x).view(batch_size, -1, H * W).permute(0, 2, 1)\n",
        "            key = self.key(x).view(batch_size, -1, H * W)\n",
        "            value = self.value(x).view(batch_size, -1, H * W)\n",
        "            attention_matrix = torch.bmm(query, key)\n",
        "            attention_map = torch.softmax(attention_matrix, dim=-1)\n",
        "            out = torch.bmm(value, attention_map.permute(0, 2, 1))\n",
        "            out = out.view(batch_size, C, H, W)\n",
        "            return self.gamma * out + x\n",
        "\n",
        "    nz = hyperparameters[\"latent_dim_nz\"]\n",
        "    ngf = hyperparameters[\"gen_feature_map_size\"]\n",
        "    ndf = hyperparameters[\"disc_feature_map_size\"]\n",
        "    nc = hyperparameters[\"num_channels\"]\n",
        "\n",
        "    class Generator(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Generator, self).__init__()\n",
        "            self.main = nn.Sequential(\n",
        "                nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False), nn.BatchNorm2d(ngf*8), nn.Mish(),\n",
        "                nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf*4), nn.Mish(),\n",
        "                nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf*2), nn.Mish(),\n",
        "                nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf), nn.Mish(),\n",
        "                SelfAttention(ngf),\n",
        "                nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False), nn.Tanh()\n",
        "            )\n",
        "        def forward(self, x): return self.main(x)\n",
        "\n",
        "    class Discriminator(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Discriminator, self).__init__()\n",
        "            self.main = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)), nn.LeakyReLU(),\n",
        "                spectral_norm(nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False)), nn.BatchNorm2d(ndf*2), nn.LeakyReLU(),\n",
        "                spectral_norm(nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False)), nn.BatchNorm2d(ndf*4), nn.LeakyReLU(),\n",
        "                SelfAttention(ndf*4),\n",
        "                spectral_norm(nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False)), nn.BatchNorm2d(ndf*8), nn.LeakyReLU(),\n",
        "                spectral_norm(nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False)),\n",
        "            )\n",
        "        def forward(self, x): return self.main(x)\n",
        "\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1: nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "    # Instanciar modelos e otimizadores\n",
        "    netG = Generator().to(device)\n",
        "    netD = Discriminator().to(device)\n",
        "    netG.apply(weights_init)\n",
        "    netD.apply(weights_init)\n",
        "    optimizerD = optim.AdamW(netD.parameters(), lr=hyperparameters[\"learning_rate_disc\"], betas=hyperparameters[\"optimizer_betas\"], weight_decay=0.01)\n",
        "    optimizerG = optim.AdamW(netG.parameters(), lr=hyperparameters[\"learning_rate_gen\"], betas=hyperparameters[\"optimizer_betas\"], weight_decay=0.01)\n",
        "\n",
        "    # Salva a arquitetura dos modelos\n",
        "    with open(os.path.join(PROJECT_PATH, 'model_architecture.txt'), 'w') as f:\n",
        "        f.write(\"================== GERADOR ==================\\n\"); f.write(str(netG))\n",
        "        f.write(\"\\n\\n================ DISCRIMINADOR ================\\n\"); f.write(str(netD))\n",
        "\n",
        "    # Setup dos arquivos de log\n",
        "    log_file_loss = os.path.join(LOGS_PATH, 'historico_treinamento.csv')\n",
        "    log_file_metrics = os.path.join(LOGS_PATH, 'evaluation_metrics.csv') # ### MUDANÇA ###\n",
        "\n",
        "    # Cria o arquivo de log de perdas com cabeçalho\n",
        "    with open(log_file_loss, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['Epoch', 'Loss_Discriminator', 'Loss_Generator'])\n",
        "\n",
        "    # ### MUDANÇA ###: Cria o arquivo de log de métricas com cabeçalho\n",
        "    with open(log_file_metrics, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['epoch_evaluated', 'frechet_inception_distance', 'inception_score_mean', 'inception_score_std'])\n",
        "\n",
        "    # Loop de Treinamento\n",
        "    epochs = hyperparameters[\"total_epochs\"]\n",
        "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "    REAL_IMAGES_PATH = \"/content/data/celebahq\" # Caminho para imagens reais não muda\n",
        "\n",
        "    print(\"Iniciando o treinamento...\")\n",
        "    for epoch in range(epochs):\n",
        "        for i, (real, _) in enumerate(dataloader):\n",
        "            # Lógica de treinamento do Discriminador e Gerador (sem alterações)\n",
        "            real = real.to(device)\n",
        "            b_size = real.size(0)\n",
        "            netD.zero_grad()\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            fake = netG(noise)\n",
        "            real_output = netD(real).view(-1)\n",
        "            fake_output = netD(fake.detach()).view(-1)\n",
        "            errD_real = torch.mean(nn.ReLU(inplace=True)(1.0 - real_output))\n",
        "            errD_fake = torch.mean(nn.ReLU(inplace=True)(1.0 + fake_output))\n",
        "            errD = errD_real + errD_fake\n",
        "            errD.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "            for _ in range(2):\n",
        "              netG.zero_grad()\n",
        "              noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "              fake = netG(noise)\n",
        "              output = netD(fake).view(-1)\n",
        "              errG = -torch.mean(output)\n",
        "              errG.backward()\n",
        "              optimizerG.step()\n",
        "\n",
        "        # Log de perdas a cada época\n",
        "        print(f\"[{epoch+1}/{epochs}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}\")\n",
        "        with open(log_file_loss, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([epoch+1, errD.item(), errG.item()])\n",
        "\n",
        "        # Salva imagens de exemplo e checkpoints em intervalos\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            with torch.no_grad():\n",
        "                fake_imgs = netG(fixed_noise).detach().cpu()\n",
        "                grid = torchvision.utils.make_grid(fake_imgs, padding=2, normalize=True)\n",
        "                plt.figure(figsize=(8,8)); plt.imshow(grid.permute(1, 2, 0))\n",
        "                plt.title(f\"Imagens Geradas na Época {epoch+1}\"); plt.axis(\"off\")\n",
        "                plt.savefig(os.path.join(IMAGES_PATH, f'epoca_{epoch+1:04d}.png')); plt.close()\n",
        "\n",
        "            checkpoint_path = os.path.join(CHECKPOINTS_PATH, f'checkpoint_epoca_{epoch+1}.pth')\n",
        "            torch.save({'epoch': epoch, 'netG_state_dict': netG.state_dict()}, checkpoint_path)\n",
        "            print(f\"Checkpoint da época {epoch+1} salvo.\")\n",
        "\n",
        "\n",
        "        # ### MUDANÇA 3: AVALIAÇÃO PERIÓDICA DAS MÉTRICAS ###\n",
        "        # Avalia na primeira época, na última, e nos intervalos definidos\n",
        "        if (epoch + 1) % hyperparameters[\"evaluation_interval\"] == 0 or (epoch + 1) == epochs or epoch == 0:\n",
        "            print(f\"\\n--- Realizando avaliação na época {epoch+1} ---\")\n",
        "\n",
        "            # Caminho específico para as imagens desta avaliação\n",
        "            current_eval_path = os.path.join(EVAL_IMAGES_BASE_PATH, f\"epoca_{epoch+1}\")\n",
        "            save_fake_images_for_evaluation(netG, device, current_eval_path, num_images=2000)\n",
        "\n",
        "            # Calcular métricas\n",
        "            metrics = calculate_metrics(\n",
        "                input1=REAL_IMAGES_PATH,\n",
        "                input2=current_eval_path,\n",
        "                cuda=True, isc=True, fid=True, verbose=False,\n",
        "                samples_find_deep=True\n",
        "            )\n",
        "\n",
        "            # Salvar métricas no arquivo CSV\n",
        "            with open(log_file_metrics, 'a', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                row = [epoch + 1] + list(metrics.values())\n",
        "                writer.writerow(row)\n",
        "\n",
        "            print(f\"--- Avaliação da Época {epoch+1} concluída. FID: {metrics.get('frechet_inception_distance'):.2f}, IS: {metrics.get('inception_score_mean'):.2f} ---\\n\")\n",
        "\n",
        "\n",
        "    print(\"Treinamento concluído!\")\n",
        "    # Plot da interpolação no final\n",
        "    plot_latent_space_interpolation(netG, device, IMAGES_PATH, hyperparameters)\n"
      ],
      "metadata": {
        "id": "iv-sVzgoTe8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_1_feature_map_128 = {\n",
        "    \"total_epochs\": 150,\n",
        "    \"evaluation_interval\": 25,\n",
        "    \"image_size\": 64,\n",
        "    \"batch_size\": 128,\n",
        "    \"latent_dim_nz\": 100,\n",
        "    \"gen_feature_map_size\": 128,\n",
        "    \"disc_feature_map_size\": 128,\n",
        "    \"num_channels\": 3,\n",
        "    \"learning_rate_gen\": 0.00002,\n",
        "    \"learning_rate_disc\": 0.00001,\n",
        "    \"optimizer_betas\": (0.5, 0.999),\n",
        "    \"dataset\": \"CelebA-HQ\",\n",
        "    \"notes\": \"Execução com feature_map=128 para testar impacto.\"\n",
        "}\n",
        "\n",
        "experiment_2_feature_map_256 = {\n",
        "    \"total_epochs\": 150,\n",
        "    \"evaluation_interval\": 25,\n",
        "    \"image_size\": 64,\n",
        "    \"batch_size\": 128,\n",
        "    \"latent_dim_nz\": 100,\n",
        "    \"gen_feature_map_size\": 256,\n",
        "    \"disc_feature_map_size\": 256,\n",
        "    \"num_channels\": 3,\n",
        "    \"learning_rate_gen\": 0.00002,\n",
        "    \"learning_rate_disc\": 0.00001,\n",
        "    \"optimizer_betas\": (0.5, 0.999),\n",
        "    \"dataset\": \"CelebA-HQ\",\n",
        "    \"notes\": \"Execução com feature_map=256 e nn.Mish. Avaliação a cada 25 epocas.\"\n",
        "}\n",
        "\n",
        "experiment_2_feature_map_256 = {\n",
        "    \"total_epochs\": 150,\n",
        "    \"evaluation_interval\": 25,\n",
        "    \"image_size\": 64,\n",
        "    \"batch_size\": 128,\n",
        "    \"latent_dim_nz\": 100,\n",
        "    \"gen_feature_map_size\": 512,\n",
        "    \"disc_feature_map_size\": 512,\n",
        "    \"num_channels\": 3,\n",
        "    \"learning_rate_gen\": 0.00002,\n",
        "    \"learning_rate_disc\": 0.00001,\n",
        "    \"optimizer_betas\": (0.5, 0.999),\n",
        "    \"dataset\": \"CelebA-HQ\",\n",
        "    \"notes\": \"Execução com feature_map=256 e nn.Mish. Avaliação a cada 25 epocas.\"\n",
        "}\n",
        "\n",
        "\n",
        "experiments_to_run = {\n",
        "    \"Experimento_Mish_FM256\": experiment_1_feature_map_256,\n",
        "    \"Experimento_Mish_FM128\": experiment_2_feature_map_128,\n",
        "}"
      ],
      "metadata": {
        "id": "GGoBdqfkWaP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop principal que executa cada experimento definido\n",
        "for name, params in experiments_to_run.items():\n",
        "    print(f\"\\n========================================================\")\n",
        "    print(f\"INICIANDO EXPERIMENTO: {name}\")\n",
        "    print(f\"========================================================\")\n",
        "    run_experiment(hyperparameters=params, experiment_name=name)\n",
        "    print(f\"\\n========================================================\")\n",
        "    print(f\"EXPERIMENTO {name} CONCLUÍDO\")\n",
        "    print(f\"========================================================\")\n"
      ],
      "metadata": {
        "id": "F43gMcbjW59O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}